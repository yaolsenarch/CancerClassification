{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30392f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run appV2_dataCleaning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bde34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0120eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyforest\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "def lemma(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(w,'v') for w in tokens]\n",
    "    return lemmatized\n",
    "\n",
    "tfidf=TfidfVectorizer(tokenizer= lemma, min_df=3, lowercase = True, ngram_range=(1,2), stop_words='english')\n",
    "features = tfidf.fit_transform(df.final).toarray()\n",
    "labels = df.result\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a33016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels.unique()\n",
    "#lablels = labels.replace({1:0, 2:1, 3:2}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca93c626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9c3220",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(labels)/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc8b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid, indices_train, indices_test = train_test_split(features, labels, df.index, test_size=0.20, random_state=0, stratify=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb01e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_valid)/len(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f067f0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(np.array(y_valid)))\n",
    "print(np.unique(np.array(y_train)))\n",
    "print(np.unique(np.array(labels)))\n",
    "print(len(np.array(y_valid)))\n",
    "print(len(np.array(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b61cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_map = {0: 1, 1: 8, 2: 2} \n",
    "y_train_weigth=y_train.map(wt_map)\n",
    "y_train_weigth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db7728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_weigth=y_valid.map(wt_map)\n",
    "y_test_weigth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fc78d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = lgb.Dataset(X_train, label=y_train)\n",
    "#valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, weight = y_train_weigth)\n",
    "dtest = xgb.DMatrix(X_valid, label=y_valid, weight = y_test_weigth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2359cb",
   "metadata": {},
   "source": [
    "## Baseline Model: \n",
    "we can get an f1 score with no effort. Hope we can beat it with parameter tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c35651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEARCH_PARAMS = {'learning_rate': 0.4,\n",
    "#                'max_depth': 15,\n",
    "#                'num_leaves': 32,\n",
    "#                'feature_fraction': 0.8,\n",
    "#                'subsample': 0.2\n",
    "#                }\n",
    "#scale_pos_weight: a weight multiplication on the positive labelThe higher the weight, \n",
    "#the greater penalty is imposed on errors on the minor class.\n",
    "#Therefore, in order to have an unbiased model, errors on the minor class need \n",
    "#to be penalised more severely.\n",
    "\n",
    "SEARCH_PARAMS = {'max_depth': 3, #default 6\n",
    "                 'subsample': 0.5, #default ,\n",
    "                 #'n_estimator' : 100, #default \n",
    "                 'learning_rate' : 0.1,\n",
    "                 'min_child_weight' : 1}\n",
    "\n",
    "FIXED_PARAMS={'objective': 'multi:softprob',\n",
    "              'eval_metric': None,\n",
    "              'metric': 'None',\n",
    "              'num_class': 3 ,\n",
    "              'random_state': 5,\n",
    "              'num_boost_round':300,\n",
    "              'early_stopping_rounds':30}\n",
    "\n",
    "params = {#'eval_metric':FIXED_PARAMS['eval_metric'],\n",
    "          'num_class':FIXED_PARAMS['num_class'],\n",
    "          'objective':FIXED_PARAMS['objective'],  \n",
    "          'random_state': FIXED_PARAMS['random_state'],\n",
    "          'disable_default_eval_metric': 1,\n",
    "          **SEARCH_PARAMS}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef556234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = np.arange(0, 1, 0.005)\n",
    "f = np.repeat(0, 200)\n",
    "Results = np.vstack([t, f]).T\n",
    "Results[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab6fb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_result = {}\n",
    "model = xgb.train(params, dtrain,                   \n",
    "                  num_boost_round=FIXED_PARAMS['num_boost_round'],\n",
    "                  evals =[(dtrain, 'train'),(dtest, 'test')],\n",
    "                  early_stopping_rounds=FIXED_PARAMS['early_stopping_rounds'],\n",
    "                  evals_result=evals_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c33e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.best_score\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb7bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(evals_result['test']['auc'])\n",
    "#xgb.plot_metric(evals_result, metric='auc_mu') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87570693",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = len(evals_result['test']['auc'])\n",
    "epochs = np.linspace(1, stop, num=67)\n",
    "plt.plot(epochs, evals_result['train']['auc'], label='AUC')\n",
    "plt.plot(epochs, evals_result['test']['auc'], label='AUC')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86460d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat= np.array([[0.6319051,  0.4340122,  0.42533597],\n",
    "             [0.6319051,  0.4340122,  0.42533597],\n",
    "             [0.6319051,  0.4340122,  0.42533597],\n",
    "             [0.6319051,  0.4340122,  0.42533597],\n",
    "             [0.6319051, 0.4340122, 0.42533597]])\n",
    "y_hat.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e14be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "def xgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label() \n",
    "    #y_hat = y_hat.reshape(y_hat.shape[0], 3) \n",
    "    #assert y_hat.shape == (238, 3)\n",
    "    print(y_hat[300:305])\n",
    "    y_hat = y_hat.argmax(axis=1)#.astype(np.float32)  \n",
    "    print(y_hat.shape)\n",
    "    print((y_true[300:305]), 'test', y_hat[300:305])\n",
    "    print (len(y_true), 'test', len(y_hat))\n",
    "    return 'f1_macro', f1_score(y_true, y_hat, average='macro')\n",
    "    \n",
    "def xgb_recall_score(y_hat, data): \n",
    "    y_true = data.get_label()\n",
    "    y_hat = y_hat.reshape(-1, 3)\n",
    "    y_hat = y_hat.argmax(axis=0).astype(np.float32)\n",
    "    return 'recall', recall_score(y_true, y_hat, average='macro')\n",
    "  \n",
    "evals_result = {}\n",
    "model = xgb.train(params, dtrain,                   \n",
    "                  num_boost_round=FIXED_PARAMS['num_boost_round'],\n",
    "                  evals =[(dtrain, 'train'),(dtest, 'test')],\n",
    "                  #evals =[(dtest, 'test')],\n",
    "                  feval=xgb_f1_score,\n",
    "                  early_stopping_rounds=FIXED_PARAMS['early_stopping_rounds'],\n",
    "                  evals_result=evals_result)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b558e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train score:'{max(evals_result['train']['f1_macro'])}'\") \n",
    "print(f\"test score:'{max(evals_result['test']['f1_macro'])}'\") \n",
    "#print(f\"train auc score:'{max(evals_result['train']['auc'])}'\") \n",
    "#print(f\"test auc score:'{max(evals_result['test']['auc'])}'\") \n",
    "#print(f\"'{id_to_interpretation[actual]}' predicted as '{id_to_interpretation[predicted]}' : {conf_mat[actual, predicted]} examples.\")\n",
    "        \n",
    "evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d5f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_xbg(evals_result = evals_result):\n",
    "    stop = len(evals_result['test']['f1_macro'])\n",
    "    epochs = np.linspace(1, stop, num=stop)\n",
    "    plt.plot(epochs, evals_result['train']['f1_macro'], label='train f1_macro')\n",
    "    plt.plot(epochs, evals_result['test']['f1_macro'], label='test f1_macro')\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "plot_xbg(evals_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13b2428",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = model.predict(dtrain)\n",
    "print('Train accuracy', f1_score(y_train, y_train_predict, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b8149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Utility.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e0a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conf_matrix(y_train, y_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd77956",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred = model.predict(dtest)\n",
    "#xgb_pred = xgb_pred.argmax(axis = 1)\n",
    "xgb_pred.shape\n",
    "xgb_pred\n",
    "xgb_F1 = recall_score(y_valid, xgb_pred, average = 'macro')\n",
    "xgb_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef04e266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_valid, xgb_pred)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "target_names = ['Negative', 'Positive', 'Intermediate']\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap=plt.cm.Blues, xticklabels=target_names, yticklabels=target_names) #cmap=plt.cm.Blues,\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec21b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e849742",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c51a5a",
   "metadata": {},
   "source": [
    "## Try out skopt.BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f8f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skopt\n",
    "from sklearn.metrics import f1_score\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "import lightgbm as lgb\n",
    "#patch below to solve TypeError: __init__() got an unexpected keyword argument 'iid'\n",
    "def bayes_search_CV_init(self, estimator, search_spaces, optimizer_kwargs=None,\n",
    "                         n_iter=50, scoring=None, fit_params=None, n_jobs=1,\n",
    "                         n_points=1, iid=True, refit=True, cv=None, verbose=0,\n",
    "                         pre_dispatch='2*n_jobs', random_state=None,\n",
    "                         error_score='raise', return_train_score=False):\n",
    "\n",
    "        self.search_spaces = search_spaces\n",
    "        self.n_iter = n_iter\n",
    "        self.n_points = n_points\n",
    "        self.random_state = random_state\n",
    "        self.optimizer_kwargs = optimizer_kwargs\n",
    "        self._check_search_space(self.search_spaces)\n",
    "        self.fit_params = fit_params\n",
    "\n",
    "        super(skopt.BayesSearchCV, self).__init__(\n",
    "             estimator=estimator, scoring=scoring,\n",
    "             n_jobs=n_jobs, refit=refit, cv=cv, verbose=verbose,\n",
    "             pre_dispatch=pre_dispatch, error_score=error_score,\n",
    "             return_train_score=return_train_score)\n",
    "        \n",
    "skopt.BayesSearchCV.__init__ = bayes_search_CV_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176cba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''opt = BayesSearchCV(\n",
    "    SVC(),\n",
    "    {\n",
    "        'C': (1e-6, 1e+6, 'log-uniform'),\n",
    "        'gamma': (1e-6, 1e+1, 'log-uniform'),\n",
    "        'degree': (1, 8),  # integer valued parameter\n",
    "        'kernel': ['linear', 'poly', 'rbf'],  # categorical parameter\n",
    "    },\n",
    "    n_iter=32,\n",
    "    cv=3\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b56f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_PARAMS = {'learning_rate': 0.3,\n",
    "                 #'num_iterations': 200,\n",
    "                 'max_depth': 6,                 \n",
    "                 #'early_stopping_round': 20,  \n",
    "                 #'min_child_weight': 1,\n",
    "                 'colsample_bytree': 0.8,\n",
    "                 'subsample': 0.8,                  \n",
    "                 'gamma': 0                 \n",
    "                } \n",
    "SEARCH_PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e496eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SPACE = [\n",
    "    skopt.space.Real(0.01, 0.2, name='learning_rate', prior='log-uniform'),\n",
    "    #skopt.space.Integer(50, 500, name='num_iterations'),\n",
    "    skopt.space.Integer(1, 30, name='max_depth'),    \n",
    "    #skopt.space.Integer(20, 50, name='early_stopping_round'),\n",
    "    #skopt.space.Real(1, 5, name='min_child_weight', prior='uniform'), \n",
    "    skopt.space.Real(0.1, 1.0, name='colsample_bytree', prior='uniform'),    \n",
    "    skopt.space.Real(0.1, 1.0, name='subsample', prior='uniform'), \n",
    "    skopt.space.Real(0, 2.0, name='gamma', prior='uniform')    \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa059042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    #y_hat = y_hat.reshape(3, -1).T    \n",
    "    y_hat = y_hat.argmax(axis=1)\n",
    "    return 'f1_macro', f1_score(y_true, y_hat, average='macro') \n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, weight = y_train_weigth)\n",
    "dtest = xgb.DMatrix(X_valid, label=y_valid, weight = y_test_weigth)\n",
    "def cv_evaluate(search_params):     \n",
    "    params = {'num_class':3,\n",
    "              'objective': 'multi:softprob',  \n",
    "              'reg_lambda': 1,\n",
    "              'disable_default_eval_metric': 1,\n",
    "              **search_params}  \n",
    "    num_boost_round = 1000\n",
    "    cv_dict = xgb.cv(params, dtrain, nfold= 5, num_boost_round=num_boost_round,\n",
    "                     early_stopping_rounds=30, \n",
    "                     seed=42, feval=xgb_f1_score)\n",
    "    return max(cv_dict['test-f1_macro-mean'])\n",
    " \n",
    "score = cv_evaluate(SEARCH_PARAMS)\n",
    "score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40f27d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@skopt.utils.use_named_args(SPACE)\n",
    "def objective(**params):\n",
    "    return -1.0 * cv_evaluate(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38f8845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = skopt.forest_minimize(objective, SPACE, n_calls=30, n_random_starts=10, random_state=0)\n",
    "best_cv_f1 = -1.0 * results.fun\n",
    "best_params_cv = results.x\n",
    "\n",
    "print('best result: ', best_cv_f1)\n",
    "print('best parameters: ', best_params_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7b68fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_params_cv['num_iterations'] = best_params_cv[2]\n",
    "#final_params_cv['early_stopping_round'] = best_params_cv[3]\n",
    "#final_params_cv['min_data_in_leaf'] = best_params_cv[5]\n",
    "\n",
    "final_params_cv = {'num_class':3,\n",
    "                   'objective': 'multi:softprob',  \n",
    "                   'reg_lambda': 1,\n",
    "                   'disable_default_eval_metric': 1,         \n",
    "          } \n",
    "final_params_cv['learning_rate'] = best_params_cv[0]\n",
    "final_params_cv['max_depth'] = best_params_cv[1]\n",
    "#final_params_cv['num_iterations'] = best_params_cv[2]\n",
    "#final_params_cv['early_stopping_round'] = best_params_cv[3]\n",
    " \n",
    "final_params_cv['colsample_bytree'] = best_params_cv[2]\n",
    "final_params_cv['subsample'] = best_params_cv[3]\n",
    "final_params_cv['gamma'] = best_params_cv[4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6712ae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_params_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a929c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_result = {}\n",
    "\n",
    "clf_cv = xgb.train(final_params_cv, dtrain,\n",
    "                   num_boost_round=num_boost_round,\n",
    "                   early_stopping_rounds=30, \n",
    "                   evals =[(dtrain, 'train'),(dtest, 'test')],\n",
    "                   feval=xgb_f1_score,\n",
    "                   evals_result=evals_result)\n",
    "\n",
    "plot_xbg(evals_result = evals_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5588a761",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(np.array(y_valid)))\n",
    "print(np.unique(np.array(y_train)))\n",
    "print(np.unique(np.array(labels)))\n",
    "print(len(np.array(y_valid)))\n",
    "print(len(np.array(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d4991",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred_cv = clf_cv.predict(dtest)\n",
    "xgb_pred_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36bfb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb_pred_cv = clf_cv.predict(dtrain)\n",
    "xgb_pred_cv = xgb_pred_cv.argmax(axis = 1)\n",
    "xgb_pred_cv.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ab7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_F1_cv = f1_score(y_valid, xgb_pred_cv, average = 'macro')\n",
    "xgb_F1_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e0bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(np.array(y_valid), xgb_pred_cv)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "target_names = ['Negative', 'Positive', 'Intermediate']\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap=plt.cm.Blues, xticklabels=target_names, yticklabels=target_names) #cmap=plt.cm.Blues,\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf6b856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out gridsearch + lgbclassfier with parameters trained with lgb.cv\n",
    "grid_param = {}\n",
    "\n",
    "for key, value in final_params_cv.items():\n",
    "    temp = []\n",
    "    temp.append(value)\n",
    "    grid_param[key]=temp\n",
    "grid_param\n",
    "grid_param.pop('early_stopping_round')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f12fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {'objective': ['multiclass'],\n",
    "              'learning_rate': [0.4],\n",
    "              'max_depth': [9],\n",
    "              'n_estimators': [75],\n",
    "              'min_child_samples': [5],\n",
    "              'min_child_weight': [0.0001],\n",
    "              'scale_pos_weight': [0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037ed43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gridsearch + lgbclassfier\n",
    "model = lgb.LGBMClassifier()\n",
    "gs = GridSearchCV(model, grid_param, cv=5, scoring=['f1_micro','precision_micro','recall_micro'], refit='f1_micro')\n",
    "gs = gs.fit(X_train, y_train)\n",
    "best_model = gs.best_estimator_\n",
    "pred = best_model.predict(X_valid)\n",
    "print('Gridsearch best F1_micro score (based on logistic regression probabilities) =', gs.best_score_)\n",
    "print('Model best F1 score =', f1_score(y_valid, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098f74e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def plot_conf_matrix(y_true, y_hat):\n",
    "    conf_mat = confusion_matrix(np.array(y_true), y_hat)\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    target_names = ['Negative', 'Positive', 'Intermediate']\n",
    "    sns.heatmap(conf_mat, annot=True, fmt='d', cmap=plt.cm.Blues, xticklabels=target_names, yticklabels=target_names) #cmap=plt.cm.Blues,\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd11aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_conf_matrix(y_valid, pred)\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(np.array(y_valid), pred)\n",
    "target_names = ['Negative', 'Positive', 'Intermediate']\n",
    "cmp = ConfusionMatrixDisplay(cm, display_labels=target_names)\n",
    "cmp.plot(cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b512e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Utility import plot_conf_matrix\n",
    "%run Utility.ipynb\n",
    "test = plot_conf_matrix(y_valid, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94056fc",
   "metadata": {},
   "source": [
    "## Tuning parameters with skopt using lgb.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d22b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5176b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_PARAMS = {'learning_rate': 0.4,\n",
    "                 'max_depth': 15,\n",
    "                 'max_bin':300,\n",
    "                 'num_leaves': 300,\n",
    "                 'min_sum_hessian_in_leaf': 0.001,\n",
    "                 'scale_pos_weight': 0.1,\n",
    "                 'feature_fraction': 0.8,\n",
    "                 'subsample': 0.2\n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74422e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''SEARCH_PARAMS = {'learning_rate': 0.4,\n",
    "                 'max_depth': 15,\n",
    "                 'num_iterations': 20,\n",
    "                 'min_data_in_leaf':5,\n",
    "                 'min_sum_hessian_in_leaf': 0.001,\n",
    "                 'scale_pos_weight': 0.1\n",
    "                }'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b8c3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def lgb_f1_score(y_hat, data):\n",
    "        y_true = data.get_label()\n",
    "        y_hat = y_hat.reshape(3, -1).T\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "        return 'f1', f1_score(y_true, y_hat, average='macro'), True\n",
    "    \n",
    "def train_evaluate(search_params):     \n",
    "    #X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "\n",
    "    params = {'metric':'None',\n",
    "              'num_class':3,\n",
    "              'objective': 'multiclass', \n",
    "              'force_col_wise': True, \n",
    "              **search_params}  \n",
    "   \n",
    "    evals_result = {}\n",
    "    \n",
    "    model = lgb.train(params, train_data, \n",
    "                      valid_sets=[valid_data, train_data], \n",
    "                      valid_names=['valid', 'train'], \n",
    "                      num_boost_round=300,\n",
    "                      early_stopping_rounds=30,\n",
    "                      feval=lgb_f1_score, evals_result=evals_result)\n",
    "    score = model.best_score['valid']['f1']\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1c553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = train_evaluate(SEARCH_PARAMS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bec86d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''SPACE = [\n",
    "    skopt.space.Real(0.01, 0.5, name='learning_rate', prior='log-uniform'),\n",
    "    skopt.space.Integer(1, 45, name='max_depth'),\n",
    "    skopt.space.Integer(25, 1500, name='num_iterations'),\n",
    "    skopt.space.Integer(5, 30, name='min_data_in_leaf'),\n",
    "    skopt.space.Real(0.0001, 0.005, name='min_sum_hessian_in_leaf', prior='uniform'),\n",
    "    skopt.space.Real(0.1, 10, name='scale_pos_weight', prior='uniform')]\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479692c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE = [\n",
    "    skopt.space.Real(0.01, 0.5, name='learning_rate', prior='log-uniform'),\n",
    "    skopt.space.Integer(1, 30, name='max_depth'),\n",
    "    skopt.space.Integer(300, 1000, name='max_bin'),\n",
    "    skopt.space.Integer(500, 1000, name='num_leaves'),\n",
    "    skopt.space.Real(0.0001, 0.005, name='min_sum_hessian_in_leaf', prior='uniform'), \n",
    "    skopt.space.Real(0.1, 10, name='scale_pos_weight', prior='uniform'),\n",
    "    skopt.space.Real(0.1, 1.0, name='feature_fraction', prior='uniform'),    \n",
    "    skopt.space.Real(0.1, 1.0, name='subsample', prior='uniform')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fb583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@skopt.utils.use_named_args(SPACE)\n",
    "def objective(**params):\n",
    "    return -1.0 * train_evaluate(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37861773",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = skopt.forest_minimize(objective, SPACE, n_calls=30, n_random_starts=10)#, random_state= 0)\n",
    "best_auc = -1.0 * results.fun\n",
    "best_params = results.x\n",
    "\n",
    "print('best result: ', best_auc)\n",
    "print('best parameters: ', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb23e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params = {'metric':'None',\n",
    "                'num_class':3,\n",
    "                'objective': 'multiclass',\n",
    "                'force_col_wise': True, \n",
    "          }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b93515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params['learning_rate'] = best_params[0]\n",
    "final_params['max_depth'] = best_params[1]\n",
    "#final_params['max_bin'] = best_params[2]\n",
    "final_params['num_leaves'] = best_params[3]\n",
    "final_params['min_sum_hessian_in_leaf'] = best_params[4]\n",
    "final_params['scale_pos_weight'] = best_params[5]\n",
    "final_params['feature_fraction'] = best_params[6]\n",
    "final_params['subsample'] = best_params[7] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff025406",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''final_params['learning_rate'] = best_params[0]\n",
    "final_params['max_depth'] = best_params[1]\n",
    "final_params['num_iterations'] = best_params[2]\n",
    "final_params['min_data_in_leaf'] = best_params[3]\n",
    "final_params['min_sum_hessian_in_leaf'] = best_params[4]\n",
    "final_params['scale_pos_weight'] = best_params[5]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd90db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9039a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_result = {}\n",
    "\n",
    "clf = lgb.train(final_params, train_data, valid_sets=[valid_data, train_data], valid_names=['valid', 'train'], feval=lgb_f1_score, evals_result=evals_result)\n",
    "\n",
    "lgb.plot_metric(evals_result, metric='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c4c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_pred = clf.predict(X_valid)\n",
    "lgb_pred = lgb_pred.argmax(axis = 1)\n",
    "lgb_pred.shape\n",
    "lgb_pred\n",
    "lgb_F1 = f1_score(y_valid, lgb_pred, average = 'macro')\n",
    "lgb_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ed570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_valid, lgb_pred)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "target_names = ['Negative', 'Positive', 'Intermediate']\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap=plt.cm.Blues, xticklabels=target_names, yticklabels=target_names) #cmap=plt.cm.Blues,\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3bfb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
